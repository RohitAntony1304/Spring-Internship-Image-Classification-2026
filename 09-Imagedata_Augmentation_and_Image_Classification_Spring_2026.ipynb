{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-header",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div align=\"left\" style=\"background-color: #008080; padding: 20px 10px;\">\n",
    "<h3><b>IDEAS - Institute of Data Engineering, Analytics and Science Foundation</b></h3>\n",
    "<p>Spring Internship Program 2026</p>\n",
    "<hr style=\"width:100%;\">\n",
    "<h3><b>Project Title:</b> Imagedata Augmentation and Image Classification</h3>\n",
    "<h4>Project Notebook</h4>\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #4285F4; padding-left: 15px;\">\n",
    "  <strong>Created by:</strong> Koustab Ghosh<sup>1</sup> & Sujoy Kumar Biswas<sup>2</sup><br>\n",
    "  <strong>Designation:</strong>\n",
    "  <ol style=\"margin-top: 5px; padding-left: 20px; font-size: 0.9em;\">\n",
    "    <li>Researcher, IDEAS-TIH, Indian Statistical Institute, Kolkata</li>\n",
    "    <li>Head of Research & Innovation, IDEAS-TIH, Indian Statistical Institute, Kolkata</li>\n",
    "  </ol>\n",
    "</blockquote>\n",
    "<hr style=\"width:100%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1-markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "points": 5
   },
   "source": [
    "### Question 1: Import Libraries and Load Image (5 Marks)\n",
    "\n",
    "Import `numpy` as `np` and `cv2`. Download the image 'moon-pexels-frank-cone.jpg' from https://drive.google.com/drive/folders/1TeLp4U4NsXCSgClbF7ODBsaLKpHSWeQr?usp=sharing and load it into a variable named `original_image` using OpenCV. Print the shape of the loaded image.\n",
    "\n",
    "**Hint:** Use `cv2.imread()` to load the image and `.shape` to get its dimensions.\n",
    "\n",
    "**Expected Output:** A tuple representing the shape of the image (height, width, channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "q1-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "original_image = cv2.imread('moon-pexels-frank-cone.jpg')\n",
    "\n",
    "print(original_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q2-markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "points": 5
   },
   "source": [
    "### Question 2: Convert to Grayscale (5 Marks)\n",
    "\n",
    "Convert the `original_image` to grayscale using OpenCV's `cvtColor` function. Store the result in a variable named `grayscale_image`. Print the shape of the new grayscale image.\n",
    "\n",
    "**Hint:** Use `cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)`. The shape of the grayscale image will have two dimensions instead of three.\n",
    "\n",
    "**Expected Output:** A tuple representing the shape of the grayscale image (height, width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q2-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grayscale_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "print(grayscale_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q3-markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "points": 5
   },
   "source": [
    "### Question 3: Save the Grayscale Image (5 Marks)\n",
    "\n",
    "Save your `grayscale_image` to a file named `graymoon.jpg`.\n",
    "\n",
    "**Hint:** Use the `cv2.imwrite('filename.jpg', image_variable)` function.\n",
    "\n",
    "**Expected Output:** No direct output, but a file named `graymoon.jpg` will be created in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q3-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv2.imwrite('graymoon.jpg', grayscale_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q4-markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "points": 10
   },
   "source": [
    "### Question 4: Shift the Image (10 Marks)\n",
    "\n",
    "Create a transformation matrix `M` to shift the `original_image` 50 pixels to the right and 100 pixels down. Apply this transformation using `cv2.warpAffine` and store the result in `shifted_image`. Print the shape of `shifted_image`.\n",
    "\n",
    "**Hint:** The matrix `M` will be a 2x3 NumPy float32 array: `np.float32([[1, 0, 50], [0, 1, 100]])`. The output shape should be the same as the original image.\n",
    "\n",
    "**Expected Output:** The shape of the shifted image, which will be identical to the original image's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "q4-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "M = np.float32([[1, 0, 50],\n",
    "                [0, 1, 100]])\n",
    "\n",
    "\n",
    "height, width = original_image.shape[:2]\n",
    "\n",
    "shifted_image = cv2.warpAffine(original_image, M, (width, height))\n",
    "\n",
    "print(shifted_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q5-markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "points": 10
   },
   "source": [
    "### Question 5: Resize the Image (10 Marks)\n",
    "\n",
    "Resize the `original_image` to be 150 pixels wide and 100 pixels tall. Store the result in a variable named `resized_image` and print its new shape.\n",
    "\n",
    "**Hint:** Use the `cv2.resize()` function. The desired size is passed as a tuple `(width, height)`.\n",
    "\n",
    "**Expected Output:** The tuple `(100, 150, 3)` representing the new shape (height, width, channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q5-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resized_image = cv2.resize(original_image, (150, 100))\n",
    "\n",
    "print(resized_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q6-markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "points": 10
   },
   "source": [
    "### Question 6: Rotate the Image (10 Marks)\n",
    "\n",
    "Rotate the `original_image` by 90 degrees counter-clockwise around its center. Store the result in a variable named `rotated_image` and print its shape.\n",
    "\n",
    "**Hint:** First, get the image dimensions. Then, create a rotation matrix using `cv2.getRotationMatrix2D(center, angle, scale)`. Finally, apply it with `cv2.warpAffine`.\n",
    "\n",
    "**Expected Output:** The shape of the rotated image. Note that the height and width will be swapped compared to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q6-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 800, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "height, width = original_image.shape[:2]\n",
    "\n",
    "center = (width // 2, height // 2)\n",
    "\n",
    "\n",
    "M = cv2.getRotationMatrix2D(center, 90, 1.0)\n",
    "\n",
    "rotated_image = cv2.warpAffine(original_image, M, (height, width))\n",
    "\n",
    "print(rotated_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7-markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "points": 10
   },
   "source": [
    "### Question 7: Download and Unzip Cat/Dog Data (10 Marks)\n",
    "\n",
    "Download the Cat and Dog image dataset from the following link https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip and then unzip it. This will create a 'Cat_Dog_data' directory.\n",
    "\n",
    "**Hint:** Download and unzip to extract the files.\n",
    "\n",
    "**Expected Output:** No direct Python output, but the cell's log should show the download and extraction process completing successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q7-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      " 46  553M   46  256M    0     0  1826k      0  0:05:10  0:02:23  0:02:47 5132k04  0:07:10 1303k 1008k07:21  0:00:43  0:06:38  573kk151M    0     0  1648k      0  0:05:43  0:01:33  0:04:10  934kM    0     0  1590k      0  0:05:56  0:02:13  0:03:43 2716k   0  1806k      0  0:05:13  0:02:22  0:02:51 5244k"
     ]
    }
   ],
   "source": [
    "!curl -O https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
    "!unzip -o Cat_Dog_data.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q8-markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "points": 15
   },
   "source": [
    "### Question 8: Create an Image Transform Pipeline (15 Marks)\n",
    "\n",
    "Import `torch` and necessary modules from `torchvision`. Define a transform pipeline named `train_transform` that resizes images to 255x255, randomly flips them horizontally, and then converts them to a tensor.\n",
    "\n",
    "**Hint:** Use `transforms.Compose()` with a list containing `transforms.Resize()`, `transforms.RandomHorizontalFlip()`, and `transforms.ToTensor()`.\n",
    "\n",
    "**Expected Output:** No output, but the `train_transform` object should be created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "q8-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((255, 255)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q9-markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "points": 15
   },
   "source": [
    "### Question 9: Create an ImageFolder Dataset (15 Marks)\n",
    "\n",
    "Create an `ImageFolder` dataset named `train_dataset` from the `'Cat_Dog_data/train'` directory, applying the `train_transform` pipeline you just created. Print the total number of images found in the dataset.\n",
    "\n",
    "**Hint:** Use `datasets.ImageFolder(data_dir, transform=your_transform)`. The number of images is the length of the dataset object, which you can get with `len()`.\n",
    "\n",
    "**Expected Output:** A printout of the number of images in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "q9-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "data_dir = \"Cat_Dog_data/train\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(data_dir, transform=train_transform)\n",
    "\n",
    "\n",
    "print(len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q10-markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "points": 15
   },
   "source": [
    "### Question 10: Create a DataLoader (15 Marks)\n",
    "\n",
    "Create a `DataLoader` named `train_loader` from the `train_dataset`. Set the `batch_size` to 64 and `shuffle` to True. Then, retrieve one batch of images and labels from the loader and print the shape of the images tensor and the labels tensor.\n",
    "\n",
    "**Hint:** Use `torch.utils.data.DataLoader()`. To get one batch, use `images, labels = next(iter(train_loader))`. Print `images.shape` and `labels.shape`.\n",
    "\n",
    "**Expected Output:** Two printed tuples representing the shapes of the image batch and the label batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "q10-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 255, 255])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
